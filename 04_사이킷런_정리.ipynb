{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04 사이킷런 정리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMskRGwsMw3C8x9DBFJZrKa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/runnin123/TIL/blob/master/04_%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0_%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaSQhEi-z_L3",
        "colab_type": "text"
      },
      "source": [
        "## 1. Estimator, fit( ), predict( )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgLxBkl80JSF",
        "colab_type": "text"
      },
      "source": [
        "- 분류 알고리즘 클래스: Classfier\n",
        "- 회귀 알고리즘 클래스: Regressor\n",
        "- Estimator 클래스: Classfier + Regressor\n",
        "- fit( ): ML 모델 학습 메서드, predict( ): 학습된 모델 예측 메서드\n",
        "- 비지도학습인 차원 축소, 클러스터링, 피처 추출 등의 클래스에서도 fit과 transform 적용 → 지도학습의 fit처럼 학습이 아닌 데이터 변환으로 작용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJzivWuT1YIW",
        "colab_type": "text"
      },
      "source": [
        "## 2. 주요 모듈\n",
        "1) 예제 데이터\n",
        "- data_sets: 사이킷런에 내장된 예제 데이터셋\n",
        "\n",
        "2) 피처 처리\n",
        "- preprocessing: 데이터 전처리 기능 제공(문자열 인코딩, 정규화, 스케일링 등)\n",
        "- feature_selection: 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업 수행\n",
        "- feature_extraction: 텍스트/이미지 데이터의 벡터화 피처 추출\n",
        "\n",
        "3) 피처 처리 + 차원 축소\n",
        "- decomposition: 차원 축소 관련 알고리즘 모듈\n",
        "\n",
        "4) 데이터 분리, 검증 + 파라미터 튜닝\n",
        "- model_selection: 교차 검증을 위한 학습/테스트 분리, 그리드 서치 제공\n",
        "\n",
        "5) 평가\n",
        "- metrics: 분류, 회귀, 클러스터링, 페어와이즈에 대한 성능 측정 방법 제공\n",
        "\n",
        "6) ML 알고리즘\n",
        "- ensemble: 앙상블 알고리즘(랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등)\n",
        "- linear_model: 선형 회귀, 릿지, 라쏘, 로지스틱 회귀 등\n",
        "- naive_bayes: 나이브 베이즈. 가우시안 NB, 다항 분포 NB 등\n",
        "- neighbors: 최근접 이웃 알고리즘. K-NN 등\n",
        "- svm: 서포트 벡터 머신 알고리즘\n",
        "- tree: 의사 결정 트리 알고리즘\n",
        "- cluster: 비지도 클러스터링 알고리즘(K-평균, 계층형, DBSCAN 등)\n",
        "\n",
        "7) 유틸리티\n",
        "- pipeline: 피처 처리 등 변환, 알고리즘 학습, 예측 등을 묶어 실행할 수 있는 유틸리티 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25MbTnze4Sck",
        "colab_type": "text"
      },
      "source": [
        "## 3. 내장된 예제 데이터셋\n",
        "1. load_boston: 회귀 ) 미국 보스턴 집 피처, 가격 데이터\n",
        "2. load_breast_cancer: 분류 ) 위스콘신 유방암 피처, 악성/음성 레이블 데이터\n",
        "3. load_diabetes: 회귀 ) 당뇨 데이터\n",
        "4. load_digits: 분류 ) 0 ~ 9까지 숫자의 이미지 픽셀 데이터\n",
        "5. load_iris: 분류) 붗꽃 피처 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLKR8onf448A",
        "colab_type": "text"
      },
      "source": [
        "데이터 셋의 딕셔너리 키\n",
        "- data: 피처 데이터 (ndarray)\n",
        "- target: 분류 → 레이블 값, 회귀 → 숫자 결과값 (ndarray)\n",
        "- target_names: 개별 레이블 이름 (ndarray / list)\n",
        "- feature_names: 피처 이름 (ndarray / list)\n",
        "- DESCR: 데이터셋, 피처 설명 (string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTUxL1uez2FD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ea9ae89-631e-4288-b358-faf227d63849"
      },
      "source": [
        "# 붓꽃 데이터 생성\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ry11nXE5gMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c088eba-7d9f-4071-f112-053c760727fe"
      },
      "source": [
        "# 붓꽃 데이터 키 값 확인\n",
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP8tu5GH55ib",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model Selection 모듈"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHgKLY3K6B6l",
        "colab_type": "text"
      },
      "source": [
        "### 1) train_test_split( )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FQlZ24H5rbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ca37298-eaa5-4e36-beaf-b7f278d4b60e"
      },
      "source": [
        "# 테스트 데이터셋 사용하지 않을 경우\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 학습\n",
        "iris = load_iris()\n",
        "df_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "df_clf.fit(train_data, train_label)\n",
        "\n",
        "# 예측 수행\n",
        "pred = df_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label, pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5z1hSdj62nE",
        "colab_type": "text"
      },
      "source": [
        "- 정확도 100% → 이미 학습한 데이터셋으로 예측했기 때문 → 테스트 데이터셋 사용해야 함 → train_test_split( )\n",
        "- test_size: 테스트 데이터의 샘플링 비율\n",
        "- train_size: 학습 데이터 샘플링 비율. 일반적으로는 test_size를 사용하므로 잘 쓰지 않음\n",
        "- shuffle: 데이터를 섞을지를 결정\n",
        "- random_state: 호출 시 동일한 학습/테스트 데이터셋 생성을 위해 주어지는 난수 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwgoDQr61Y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트 데이터 30%, 학습 데이터 70%, random_state = 121\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state = 121)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIRxh6fnJKCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab16fc0b-3f65-4b9b-bfa6-5db5562b52b4"
      },
      "source": [
        "# 학습, 예측\n",
        "df_clf.fit(X_train, y_train)\n",
        "pred = df_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldMH25yMJb0N",
        "colab_type": "text"
      },
      "source": [
        "### 2) 교차 검증\n",
        "- 해당 테스트 데이터에만 과적합되는 학습 모델 → 다른 테스트 데이터가 들어올 경우 성능이 저하됨 → 교차 검증을 이용해 다양한 학습, 평가 수행\n",
        "- 데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터, 검증 데이터에서 학습, 평가 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow3yL_-WJ991",
        "colab_type": "text"
      },
      "source": [
        "2-1) K 폴드 교차 검증\n",
        "- K개의 데이터 폴드 세트 생성 → K번만큼 각 폴드 세트에 학습, 검증 평가를 반복 수행 → 평가의 평균 결과로 예측 성능 평가\n",
        "- KFold, StratifiedKFold 클래스 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEF08FbNJXjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7158b427-16c6-4ccc-964c-85d3525df120"
      },
      "source": [
        "# K 폴드 교차 검증\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 로드, 의사 결정 트리 객체 생성\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "df_clf = DecisionTreeClassifier(random_state = 156)\n",
        "\n",
        "# KFold(K = 5) 객체, 폴드 세트별 정확도를 담을 리스트 생성\n",
        "kfold = KFold(n_splits = 5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:', features.shape[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv3P95zNLLdi",
        "colab_type": "text"
      },
      "source": [
        "- 붓꽃 데이터셋 크기: 150 → 학습 데이터 = 4/5인 120개, 검증 데이터 = 1/5인 30개\n",
        "- split( ) 호출 → 학습/검증 데이터로 분할할 수 있는 인덱스 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQXhUEVCLCGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "0f5b8513-55c8-4bae-9c43-bfb255355c02"
      },
      "source": [
        "# split() 호출, 교차 검증 수행 시 학습,검증 반복 → 예측 정확도 측정\n",
        "n_iter = 0\n",
        "\n",
        "# split() 호출\n",
        "for train_index, test_index, in kfold.split(features):\n",
        "  # 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  \n",
        "  # 학습, 예측\n",
        "  df_clf.fit(X_train, y_train)\n",
        "  pred = df_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "\n",
        "  # 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration별 정확도 합 → 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_zOeUajNRUO",
        "colab_type": "text"
      },
      "source": [
        "2-2) Stratified K 폴드\n",
        "- 불균형한 분포도를 가진 레이블 데이터를 위한 K 폴드 방식\n",
        "- 예) 대출 사기 데이터 → 대부분이 정상 대출, 대출 사기의 경우 극소수 → 랜덤하게 인덱스를 골라도 0과 1의 비율이 정상적이지 못함\n",
        "- Stratified K 폴드: 원본 데이터의 레이블 분포 고려, 이 분포와 동일하게 데이터셋을 분배"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiRkZgv0LEXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d17334cc-dde3-4131-9590-fcca8b982430"
      },
      "source": [
        "# 붓꽃 데이터 로드\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTRzAoIJOMww",
        "colab_type": "text"
      },
      "source": [
        "- 레이블 값: 각각 50개 씩으로 모두 동일\n",
        "- 3개 폴드셋을 KFold로 생성, 교차 검증 시 생성되는 값 분포도 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px8YFCb3OMDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "b47705fc-88fb-41b8-dc02-a370f7d83648"
      },
      "source": [
        "# K Fold 사용\n",
        "kfold = KFold(n_splits = 3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  \n",
        "  print('## 교차 검증:{0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증:1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증:2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증:3\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKjCV1tnPm9e",
        "colab_type": "text"
      },
      "source": [
        "- 첫 번째 교차 검증의 경우, 학습 데이터가 2, 1이 50개씩, 0의 데이터를 전혀 학습하지 못하며 0의 데이터를 전혀 예측하지도 못함 → StratifiedKFold 사용\n",
        "- 레이블 데이터 분포도를 고려하기 때문에 인자에 레이블 데이터셋 입력 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmCA3Ef3PLrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "cd23e2e4-e78a-47c1-f1e3-a798eee224a1"
      },
      "source": [
        "# Stratified K Fold 사용\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits = 3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter += 1\n",
        "\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "\n",
        "  print('## 교차 검증:{0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증:1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증:2\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증:3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-MlyhzOQ-T-",
        "colab_type": "text"
      },
      "source": [
        "- 학습 데이터와 검증 데이터가 약 1/3씩 균등한 분포로 할당되었음\n",
        "- 0, 1, 2 모두 학습 가능하며 또한 검증 가능 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndvJdfoORP6V",
        "colab_type": "text"
      },
      "source": [
        "2-3) cross_val_score( )\n",
        "- 교차 검증을 좀 더 편리하게 수행할 수 있게 해주는 API\n",
        "- 폴드 셋 설정, for 루프 반복으로 인덱스 추출, 반복 학습 및 예측 수행, 성능 측정을 한번에 수행\n",
        "- cross_val_score(estimator, X, y = None, scoring = None, cv = None, n_job = 1, verbose = 0, fit_params = None, pre_dispatch = '2*n_jobs')\n",
        "- estimator: 분류 또는 회귀 알고리즘 클래스\n",
        "- X: 피처 데이터셋\n",
        "- y: 레이블 데이터셋\n",
        "- scoring: 예측 성능 평가 지표\n",
        "- cv: 교차 검증 폴드 수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CtZK9MBQ7vx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7a0e16ec-f288-4804-9ca0-b0058a17836d"
      },
      "source": [
        "# cross_val_score() 활용\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "df_clf = DecisionTreeClassifier()\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표: 정확도, 교차 검증 세트: 3\n",
        "scores = cross_val_score(df_clf, data, label, scoring = 'accuracy', cv = 3)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 1.  ]\n",
            "평균 검증 정확도: 0.9733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmDlt1AhSvFc",
        "colab_type": "text"
      },
      "source": [
        "3) GridSearchCV\n",
        "- 교차 검증 기반, 데이터셋을 학습/테스트 셋으로 자동 분할 → 파라미터를 순차적 적용, 최적의 파라미터 도출\n",
        "- 주요 파라미터)\n",
        "- estimator: classfier, regressor, pipeline 등\n",
        "- param_grid: 파라미터 명 + 파라미터 값들 → 딕셔너리 형태로\n",
        "- scoring: 예측 성능 측정 평가 방법\n",
        "- cv: 교차 검증을 위한 학습/테스트 세트 개수 지정\n",
        "- refit: 최적의 하이퍼 파라미터를 찾은 후 해당 하이퍼 파라미터로 재학습. 기본값 = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY-BfgM6Slqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GridSearchCV 활용\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터 로드 및 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state = 121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "# 파라미터 설정\n",
        "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Ov9HvtXxMN",
        "colab_type": "text"
      },
      "source": [
        "- GridSearchCV에 fit 메서드 수행 → 결과를 cv_results_ 속성에 기록\n",
        "- cv_results_: 딕셔너리 형태. key 값과 리스트 형태의 value 값 가짐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7jt5ssXXQXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "fddfca09-a89e-467d-d127-6360d61031b9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid 하이퍼 파라미터 → 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
        "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv = 3, refit = True)\n",
        "\n",
        "# 붓꽃 학습 데이터 → 하이퍼 파라미터 순차적 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# 결과 추출, DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  ...  split2_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}  ...               0.70\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}  ...               0.70\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}  ...               0.95\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}  ...               0.95\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}  ...               0.95\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}  ...               0.95\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1VZ4R9kYT6Z",
        "colab_type": "text"
      },
      "source": [
        "- best_params_: 최고 성능을 나타낸 하이퍼 파라미터 값\n",
        "- best_score_: 그 때의 평가 결과 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjg1OBcFYJRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1caa75af-bc18-4d87-9a1e-bba9fd02e9b2"
      },
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도:0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7nWJthjY617",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f3bedc0-b665-4195-f2b3-e063dcef43e0"
      },
      "source": [
        "# refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# 예측 수행\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 셋 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 셋 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfLFFb1eZkVa",
        "colab_type": "text"
      },
      "source": [
        "## 5. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWL-D1QSZqo8",
        "colab_type": "text"
      },
      "source": [
        "### 1) 데이터 인코딩\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLXbhK7_aF9V",
        "colab_type": "text"
      },
      "source": [
        "1-1) 레이블 인코딩\n",
        "- 카테고리 피쳐 → 코드형 숫자 값으로 변환\n",
        "- LabelEncoder 클래스로 구현\n",
        "- 객체 생성 후 fit( ), transform( )로 인코딩 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_9XsLMnZQ9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ff3911e-b932-4d45-a219-8633dc751ec1"
      },
      "source": [
        "# 레이블 인코딩\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 인코더 객체 성성 후 수행\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:', labels)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iJ4yqKia_oU",
        "colab_type": "text"
      },
      "source": [
        "- 문자열 값이 어떤 숫자값으로 인코딩 되었는지 확인: classes_ 속성값 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvwuKW4fa7pR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b766e057-bc9e-4bcd-decd-8eb7cda10e09"
      },
      "source": [
        "print('인코딩 클래스:', encoder.classes_)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOfBO2ebKO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8ad59ba-b2c2-4ca4-efa2-4562584c0e9d"
      },
      "source": [
        "# inverse_transform: 디코딩\n",
        "print('디코딩 원본값:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENmD4b6MbfKo",
        "colab_type": "text"
      },
      "source": [
        "- 문자열 값이 숫자형 카테고리로 변환됨 → 1과 2가 카테고리형 숫자가 아닌 대소 비교로 인식될 가능성이 존재 → 회귀 알고리즘에는 적용 X\n",
        "- 위의 문제점을 해결하기 위한 인코딩: 원-핫 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiT8t3iabxX1",
        "colab_type": "text"
      },
      "source": [
        "1-2) 원-핫 인코딩\n",
        "- 피처 값 유형에 따라 새로운 피처 추가, 고유 값에 해당하는 칼럼에만 1을 표시, 나머지는 0을 표시\n",
        "- OneHotEncoder 사용\n",
        "- 사용하기 전 모든 문자열 값이 숫자형 값으로 변환되어야 함\n",
        "- 입력 값으로 2차원 데이터 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlkFa53sbWZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "0cb9d50f-d4eb-47c1-af3d-b71a820c3cf7"
      },
      "source": [
        "# 원-핫 인코딩\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 숫자 값 변환을 위한 라벨 인코딩\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "# 2차원 데이터로 변환\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# 원-핫 인코딩 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원-핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원-핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzdbUPv19mvf",
        "colab_type": "text"
      },
      "source": [
        "- 8개 레코드, 1개 칼럼 원본 데이터 → 8개 레코드, 6개 칼럼 데이터\n",
        "- get_dummies( ) API: 문자열을 숫자 형으로 변환할 필요 없이 바로 원-핫 인코딩 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqP0N3GC9k_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "033fa284-02d2-480d-a048-5b2f80e860dd"
      },
      "source": [
        "#get_dummies()\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'items':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items_TV</th>\n",
              "      <th>items_냉장고</th>\n",
              "      <th>items_믹서</th>\n",
              "      <th>items_선풍기</th>\n",
              "      <th>items_전자레인지</th>\n",
              "      <th>items_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n",
              "0         1          0         0          0            0          0\n",
              "1         0          1         0          0            0          0\n",
              "2         0          0         0          0            1          0\n",
              "3         0          0         0          0            0          1\n",
              "4         0          0         0          1            0          0\n",
              "5         0          0         0          1            0          0\n",
              "6         0          0         1          0            0          0\n",
              "7         0          0         1          0            0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svr63zH5-aP5",
        "colab_type": "text"
      },
      "source": [
        "### 2) 피처 스케일링과 정규화\n",
        "- 피처 스케일링: 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "- 표준화와 정규화가 있음\n",
        "- 표준화: 피처 각각을 평균 0, 분산 1인 가우시안 정규 분포 값으로 변환(평균을 빼고 표준편차로 나눈 값)\n",
        "- 정규화: 서로 다른 피처 크기를 통일하기 위해 0 ~ 1 사이의 값으로 변환(피처에서 최소값을 뺀 값을 최대값과 최소값의 차로 나눈 값)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlR_AwW-_Ou9",
        "colab_type": "text"
      },
      "source": [
        "2-1) StandardScaler\n",
        "- 표준화를 지원하는 클래스\n",
        "- 가우시안 정규 분포(평균 = 0, 분산 = 1)로 변환\n",
        "- SVM, 선형 회귀, 로지스틱 회귀 → 가우시안 분포를 가정하기 때문에 사전 표준화가 매우 중요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TjqEpWY-Or0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "e37f8956-baba-4b28-e7bc-99de29cc5560"
      },
      "source": [
        "# 붓꽃 데이터 평균, 분산 확인\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
        "\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_NUMAZACmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "17b634d9-c7e3-43b8-a03a-238186ec0c6d"
      },
      "source": [
        "# StandardScaler 이용, 표준화\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 객체 생성\n",
        "scaler = StandardScaler()\n",
        "# 데이터셋 변환\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# 스케일 변환된 데이터셋 → ndarray → DataFrame\n",
        "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZBhXnZxBejp",
        "colab_type": "text"
      },
      "source": [
        "- 평균이 0에 가까운 값, 분산 역시 1에 가까운 값으로 변환되었음을 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP6nQ2vABivB",
        "colab_type": "text"
      },
      "source": [
        "2-2) MinMaxScaler\n",
        "- 데이터를 0과 1 사이의 값으로 변환(음수값이 존재할 경우 -1 ~ 1 사이의 값)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlC5FECYBXKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "ad25a179-b95c-4815-be3b-fb4186e77c9f"
      },
      "source": [
        "# MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# 데이터셋 변환\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# 스케일 변환된 데이터셋 → ndarray → DataFrame\n",
        "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
        "print('feature들의 최소값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최대값')\n",
        "print(iris_df_scaled.max())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 최소값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "\n",
            "feature들의 최대값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc-5m40AUyNc",
        "colab_type": "text"
      },
      "source": [
        "- 최대값 1, 최소값 0이 됨을 확인할 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O2K-A64VBQd",
        "colab_type": "text"
      },
      "source": [
        "2-3) 스케일링 변환 시 유의점\n",
        "- scaler 객체 이용, 학습 데이터에 fit( ), transform( ) 적용 시, 테스트 데이터에는 fit( )을 수행하지 않고 fit( )된 학습 데이터 결과로 transform( ) 적용해야 함\n",
        "- 테스트 데이터로 새로운 스케일링 정보를 만들 경우, 학습 데이터와 스케일링 기준이 달라져 올바른 예측이 되지 않음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udcjLcZiUxCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트 데이터에 fit() 적용 시 발생하는 문제 확인\n",
        "\n",
        "# 데이터 준비\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# 학습 데이터: 0 ~ 10\n",
        "# 테스트 데이터: 0 ~ 5\n",
        "# 2차원 데이터를 위해 차원 변경\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange(0, 6).reshape(-1, 1)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUp2TmMZWPdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bd6cc0cf-250a-4b09-9ed0-6b2a85200667"
      },
      "source": [
        "# MinMaxScaler 적용\n",
        "scaler = MinMaxScaler() # feature_range 디폴트 값: 0 ~ 1\n",
        "\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array) # 최대값이 10이므로 1/10 scale로 변환됨\n",
        "\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOhfii6uXMPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1fd9985-b2b8-4c01-a20d-0b6bc5b10790"
      },
      "source": [
        "# 테스트 데이터셋 변환\n",
        "scaler.fit(test_array) \n",
        "test_scaled = scaler.transform(test_array) # test_array → 최소값 0, 최대값 5이므로 다시 fit할 경우 1/5 scale로 변환됨\n",
        "\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJwsmn7kXm9P",
        "colab_type": "text"
      },
      "source": [
        "- 학습 데이터와 테스트 데이터의 스케일링이 서로 일치하지 않음\n",
        "- 학습 데이터의 10과 테스트 데이터의 5가 동일하게 1로 스케일됨\n",
        "- 스케일링 기준: 반드시 학습 데이터를 따라야 하며, 테스트 데이터의 1은 1/10로 적용되어 0.1이 되어야 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f425QVjXj60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fa1905e2-2038-403c-dd46-31abf41e0291"
      },
      "source": [
        "# 오류 발생 방지\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array 스케일 변환 → transform()으로 변환만 해야함\n",
        "test_scaled = scaler.transform(test_array) # scaler: train_array의 스케일 적용되어 있음\n",
        "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srfnI5_OYbos",
        "colab_type": "text"
      },
      "source": [
        "- 가능하다면 전체 데이터를 스케일링 변환한 후 학습/테스트 분리\n",
        "- 불가피할 경우 테스트 데이터 변환 시 transform( )만 적용"
      ]
    }
  ]
}