## 1.데이터 취득, 데이터 가공
- 데이터 취득: 데이터를 여러 소스로부터 분석 플랫폼으로 읽어 들이는 것
- 데이터 가공: 데이터를 분석 플랫폼 안에서 필요한 모양으로 가공해내는 것

## 2.데이터 취득
- 표 형태 텍스트, 엑셀(xls, xlsx, csv), DB, 다른 SW용 이진(binary) 파일

### 보스턴 주택 데이터 세트
```R
boston <- read.table('housing.data')
library(dplyr)
glimpse(boston) # dplyr의 glimpse: 데이터 구조, 내용 파악
names(boston) <- c('crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv')
glimpse(boston)

plot(boston) # 산점도 행렬
summary(boston) # 요약 통계량
```

## 3. 데이터 출력
- write.table(), write.csv(), read_csv(), write_csv() 정도가 대표적으로 사용됨

## 4. 데이터 가공
- 데이터 분석 작업 시간의 70~80%를 소요
- 불분명한 데이터를 추리고(filter, select), 조합하고(join), 정렬하여(arrange) 의미 있는 필요한 정보를 만들어내는 과정

## 5. 데이터 가공 도구
- 1) SQL: 어디까지 SQL로 가공하고 어디부터 R로 가공할지 결정하기 위해선 둘다 익혀두는 것이 필요
- 2) 유닉스 쉘
- 3) 파이썬: 데이터 취득, 가공, 자동화 등에서 R보다 훨씬 효율적이고 편리함
- 4) R: 데이터 가공이 가장 많이 이루어지는 곳

```R
library(dplyr)

# tbl_df(): 현재 스크린에 표시될 정도의 행과 열만 출력해줌
i2 <- tbl_df(iris)
class(i2)
i2
# glimpse: 데이터 프레임을 전치, 모든 변수를 다 볼 수 있게 해줌
glimpse(i2)
# %>%(파이프 연산자)
iris %>% head # head(iris)와 동일
iris %>% head(10) # head(iris, 10)와 동일

# dplyr의 주요 동사
# filter(df, 필터링 조건): 행 선택
filter(gapminder, country == 'Korea, Rep.')
filter(gapminder, year==2007)
# arrange(): 행을 변수들의 오름차순으로 정렬
arrange(gapminder, year, country)
# select(): 필요한 열만 선택
select(gapminder, pop, gdpPercap)
# mutate(): 기존 변수들을 변환한 결과를 기존 변수나 새 변수에 할당
gapminder %>%
  mutate(total_gdp = pop*gdpPercap,
         le_gdp_ratio = lifeExp / gdpPercap,
         lgrk = le_gdp_ratio*100)
# summarize(): 요약 통계량 계산
gapminder %>%
  summarize(n_obs = n(),
            n_countries = n_distinct(country),
            n_years = n_distinct(year),
            med_gdpc = median(gdpPercap),
            max_gdpc = max(gdpPercap))
```
