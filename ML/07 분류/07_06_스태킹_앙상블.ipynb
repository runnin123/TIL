{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07-06 스태킹 앙상블.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Qs2e1JGvQ4"
      },
      "source": [
        "## 스태킹 앙상블\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5vx0iOFG0zt"
      },
      "source": [
        "- 스태킹 : 개별적 알고리즘을 서로 결합해 결과를 도출함   \n",
        "→ 배깅, 부스팅과 유사하지만, 개별 알고리즘으로 예측한 데이터를 기반으로 다시 예측을 수행한다는 점에서 큰 차이점을 보임\n",
        "- 개별 알고리즘 → 예측 결과 데이터셋 생성 → 최종적인 메타 데이터셋으로 만들어 재학습 → 최종 예측 수행\n",
        "- 필요 모델 : 개별적인 기반 모델 + 최종 메타 모델\n",
        "- 현실에 적용하는 경우는 많이 없으며, 캐글 등의 대회에서 주로 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMcfbE2zHiLv"
      },
      "source": [
        "### 기본 스태킹 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZwXCHGgGnZD"
      },
      "source": [
        "# 라이브러리, 패키지 임포트 및 데이터 로드/분할\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "\n",
        "X_data = cancer_data.data\n",
        "y_label = cancer_data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3M-zlWvJKsP"
      },
      "source": [
        "개별 모델 : KNN, 랜덤 포레스트, 결정 트리, 에이다 부스트   \n",
        "최종 모델 : 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x9ZC3LbIirX"
      },
      "source": [
        "# 개별 머신러닝 모델 생성\n",
        "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
        "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "ada_clf = AdaBoostClassifier(n_estimators = 100)\n",
        "\n",
        "# 최종 모델 생성\n",
        "lr_final = LogisticRegression(C = 10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbiKvsmPJepk",
        "outputId": "df3a6340-7bd6-4b58-b11c-73d7713ab6f4"
      },
      "source": [
        "# 개별 모델 학습\n",
        "knn_clf.fit(X_train, y_train)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=100, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TID2reTGJn_B",
        "outputId": "088b0334-042c-4849-9a51-66953d011017"
      },
      "source": [
        "# 개별 모델의 예측 데이터셋 생성, 개별 모델 정확도 측정\n",
        "knn_pred = knn_clf.predict(X_test)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "ada_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
        "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
        "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "print('에이다부스트 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN 정확도: 0.9211\n",
            "랜덤 포레스트 정확도: 0.9649\n",
            "결정 트리 정확도: 0.9123\n",
            "에이다부스트 정확도: 0.9561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRz6A4LHKRW8"
      },
      "source": [
        "개별 모델의 예측값 → 칼럼 레벨로 옆으로 붙여 피처 값으로 생성   \n",
        "→ 최종 모델의 학습 데이터로 재사용   \n",
        "예측 데이터 셋 : 1차원 ndarray → 행 형태로 붙인 뒤 transpose( )로 열 위치로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxrX-50cKLgA",
        "outputId": "aa2bbf69-e527-4dac-be1e-b2f57fd8c973"
      },
      "source": [
        "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
        "print(pred.shape)\n",
        "\n",
        "pred = np.transpose(pred)\n",
        "print(pred.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 114)\n",
            "(114, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcI1dBSmKvY6",
        "outputId": "5f3264f4-b2bc-40f1-b8ed-e6ca3eb13129"
      },
      "source": [
        "# 최종 모델 학습\n",
        "lr_final.fit(pred, y_test)\n",
        "final = lr_final.predict(pred)\n",
        "\n",
        "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 메타 모델의 예측 정확도: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAAkFr1XLHzK"
      },
      "source": [
        "### CV 세트 기반 스태킹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHXNRA9pLJds"
      },
      "source": [
        "과적합 개선을 위해 개별 모델들이 각각 교차 검증 수행 → 최종 모델을 위한 학습용 스태킹 데이터/예측을 위한 테스트용 스태킹 데이터 생성 → 최종 모델 학습 및 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuqqSoXLdES"
      },
      "source": [
        "1. 각 모델별 예측 결과 값을 기반으로 학습용/테스트용 데이터 생성\n",
        "2. 1에서 만들어진 학습용/테스트용 데이터 → 스태킹 형태로 합쳐 최종 학습용/테스트 데이터 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36vcY7NKMK2o"
      },
      "source": [
        "과정 1 코드 구현 )\n",
        "- 개별 모델이 최종 모델을 위한 데이터를 생성하는 과정\n",
        "- get_stacking_base_datasets( ) : 개별 모델의 Classifier 객체, 학습용 피처 데이터, 학습용 레이블 데이터, 테스트 피처 데이터, K 폴드의 갯수를 파라미터로 받음   \n",
        "→ 폴드 수 만큼 반복 수행, 폴드된 학습 데이터로 학습 후 예측 결과값을 기반으로 최종 모델을 위한 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojPaz-IEMHfz"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
        "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
        "    # 지정된 n_folds값으로 KFold 생성.\n",
        "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
        "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
        "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
        "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
        "    print(model.__class__.__name__ , ' model 시작 ')\n",
        "    \n",
        "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
        "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
        "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
        "        X_tr = X_train_n[train_index] \n",
        "        y_tr = y_train_n[train_index] \n",
        "        X_te = X_train_n[valid_index]  \n",
        "        \n",
        "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
        "        model.fit(X_tr , y_tr)       \n",
        "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
        "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
        "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
        "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
        "            \n",
        "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
        "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
        "    \n",
        "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
        "    return train_fold_pred , test_pred_mean"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLVYiF8CMv3u",
        "outputId": "49f360c6-26cf-4912-de0d-da5894b1096d"
      },
      "source": [
        "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
        "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
        "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
        "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n",
            "RandomForestClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n",
            "DecisionTreeClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n",
            "AdaBoostClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u09vxmhaMz6f"
      },
      "source": [
        "과정 2 코드 구현 )\n",
        "- get_stacking_base_datasets( )로 반환된 각 모델별 학습 데이터와 테스트 데이터를 합치는 과정   \n",
        "→ 넘파이 concatenate( ) 이용 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xVZg1NvMxe-",
        "outputId": "546d7358-8e25-48f7-f685-78db69f29982"
      },
      "source": [
        "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
        "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
        "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
        "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape, '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 Shape: (114, 30)\n",
            "스태킹 학습 피처 데이터 Shape: (455, 4) 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9QF6mlSNP9p"
      },
      "source": [
        "Stack_final_X_train : 최종 모델이 학습할 학습용 피처 데이터 셋   \n",
        "Stack_final_X_test : 최종 모델이 예측할 테스트용 피처 데이터 셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pKn5rD2NJD1",
        "outputId": "e0623e19-53e8-4f9f-9ce7-a9434c34ef14"
      },
      "source": [
        "# 최종 모델 학습 및 정확도 측정\n",
        "lr_final.fit(Stack_final_X_train, y_train)\n",
        "stack_final = lr_final.predict(Stack_final_X_test)\n",
        "\n",
        "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 메타 모델의 예측 정확도: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2TXpsORNpz-"
      },
      "source": [
        "하이퍼 파라미터 튜닝을 하지는 않았으나, 일반적으로 개별 모델의 하이퍼 파라미터 튜닝을 끝마친 뒤 스태킹 모델을 만드는 것이 일반적"
      ]
    }
  ]
}